## 基础

### 三大范式

每列都是不可再分的最小单元

每列都和主键间接相关

每列都和主键直接相关 == 每张表只讲一件事

### MySQL中varchar和char的区别是什么？

1、char字段的最大长度为255字符，varchar字段的最大长度为65535个字符

2、char类型如果存的数据量小于最大长度，剩余的空间会使用空格填充

### join和left join的区别？

- join等价于inner join内连接，是返回两个表中都有的符合条件的行。
- left join左连接，是返回左表中所有的行及右表中符合条件的行。
- right join右连接，是返回右表中所有的行及左表中符合条件的行。

### select的执行过程？

**连接**：首先客户端和MySQL通过三次握手建立连接。MySQL正常运行的话就去校验用户名和密码，如果认证信息错误也会报错。检验通过之后连接器会获取用户权限并且保存起来，后续的任何操作都会基于开始的读到权限进行判断，即便创建连接之后更改了权限也不会影响已连接的权限。

长连接

- **定期断开长连接**
- **客户端主动重置连接**：mysql_reset_connection 函数

**SQL解析**：词法分析和语法分析

**执行SQL**：

prepare预处理：检查SQL查询的表或者字段是否存在、有*就将它扩展为SQL的所有的列

optimize优化：有索引会选择走了哪个索引

execute执行阶段：执行器会与存储引擎交互

### update的执行过程？

执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取一行记录：

- 如果记录所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新；
- 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。

执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：

- 如果一样的话就不进行后续更新流程；
- 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作；

开启事务，首先要记录相应的 undo log，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。

InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。

在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。

两阶段提交：

- **prepare 阶段**：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
- **commit 阶段**：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）；

### count性能比较？掌握

count(*)=count(1)>count(主键)>count(字段)

MySQL 会将星号参数转化为参数 0 来处理，所以count(*) 和count(1)相等。count(主键)需要判断主键是否为空值；count(字段)会进行全表扫描，效率最差。

### drop、truncate和delete的区别？

1、drop删除整张表和表结构，以及表的索引、约束和触发器；truncate只删除表数据，表的结构、索引、约束等会被保留； delete只删除表的全部或部分数据，表结构、索引、约束等会被保留。

2、delete语句为DML(data maintain Language)，执行删除操作的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存以便进行进行回滚操作；truncate、drop是DLL(data define language)，删除行是不能恢复的，并且在删除的过程中不会激活与表有关的删除触发器，执行速度快，原数据不放到rollback segment中，不能回滚。

3、执行速度drop>truncate>delete，delete 是逐行执行的，并且在执行时会把操作日志记录下来，以备日后回滚使用，所以 delete 的执行速度是比较慢的；而 truncate 的操作是先复制一个新的表结构，再把原先的表整体删除，所以它的执行速度居中，而 drop 的执行速度最快。

### MySQL会出现死锁吗，怎么检测死锁？重要

如果 update 语句的 where 条件没有用到索引列，那么就会全表扫描，在一行行扫描的过程中，不仅给行记录加上了行锁，还给行记录两边的空隙也加上了间隙锁，相当于锁住整个表，然后直到事务结束才会释放锁

**行锁会发生死锁，表锁不会。**

解决办法：

- **设置事务等待锁的超时时间**：参数 innodb_lock_wait_timeout 是用来设置超时时间
- **开启主动死锁检测**：参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑

## 事务

###  MySQL之事务的四大特性(ACID)？

- 持久性：通过 redo log来保证的
- 原子性：通过 undo log来保证的
- 隔离性：通过 MVCC 或锁机制来保证的
- 一致性：通过持久性+原子性+隔离性来保证

### 并发事务会出现什么问题？

脏读：读到了其他事务未提交的数据

不可重复读：不同的时刻读到的同一批数据可能是不一样的

幻读：针对数据插入操作来说的

可重复读

### MySQL的事务隔离级别？

**读未提交**：指一个事务还没提交时，它做的变更就能被其他事务看到。

**读提交：指一个事务提交之后，它做的变更才能被其他事务看到。

**可重复读**：指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，**MySQL InnoDB 引擎的默认隔离级别**。

**串行化**：会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

### MVVC实现原理？

Read View 有四个重要的字段：

- 当前数据库中活跃事务的事务 id 列表

- 当前数据库中活跃事务中事务 id 最小的事务
- 创建 Read View 时当前数据库中应该给下一个事务的 id 值
- 创建该 Read View 的事务的事务 id

每行的隐藏列

- trx_id，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**。
- roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。

一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：

- 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对当前事务**可见**。
- 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**。
- 如果记录的 trx_id 值在 Read View 的min_trx_id和max_trx_id之间，需要判断 trx_id 是否在 m_ids 列表中：
  - 如果记录的 trx_id **在** m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着(还没提交事务)，所以该版本的记录对当前事务**不可见**。
  - 如果记录的 trx_id **不在** m_ids 列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。

### 幻读是如何解决的？

**快照读**（普通 select 语句）：是**通过 MVCC 方式解决了幻读**

**当前读**（select ... for update 等语句）：是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入。

- 对于快照读， MVCC 并不能完全避免幻读现象。当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。
- 对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。

即**MySQL 可重复读隔离级别并没有彻底解决幻读，只是很大程度上避免了幻读现象的发生。**

**尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句**，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。

## 索引

### MySQL什么使用B+树来作索引，它的优势什么？

定义：B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，每个节点里的数据是**按主键顺序存放**的。

对比：

- **B+Tree 对比 B Tree**：B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。B+Tree 叶子节点采用的是双链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。
- **B+Tree 对比 二叉树**：数据达到千万级别时，B+Tree 的高度依然维持在 3~4 层左右，一次数据查询操作只需要做 3~4 次的磁盘 I/O 操作就能查询到。二叉树的每个父节点的儿子节点个数是 2 个，意味着其搜索复杂度为 O(logN)，二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。
- **B+Tree 对比 Hash**：Hash在做等值查询的时候效率高，搜索复杂度为 O(1)。但是 Hash 表不适合做范围查询。

###  索引有哪些

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。

### 什么是最左匹配原则？

使用联合索引时，存在**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配。使用联合索引进行查询的时候，如果不遵循**最左匹配原则**，联合索引会失效。

### 使用索引会有那些缺陷？

虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL 不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息。

### 什么时候需要/不需要创建索引？

**使用索引**：

- **表的主关键字**：自动建立唯一索引
- **表的字段唯一约束**：利用索引来保证数据的完整
- **直接条件查询的字段**：经常用于WHERE查询条件的字段，这样能够提高整个表的查询速度
- **查询中与其它表关联的字段**：例如字段建立了外键关系
- **查询中排序的字段**：排序的字段如果通过索引去访问将大大提高排序速度
- **查询中统计或分组统计的字段**：经常用于 GROUP BY 和 ORDER BY 的字段，可以创建联合索引

**不用索引**：

- **表记录太少**：表数据太少的时候，不需要创建索引
- **经常插入、删除、修改的字段**：经常更新的字段不用创建索引，索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，会影响数据库性能
- **数据重复且分布平均的表字段**：假如一个表有10万行记录，性别只有男和女两种值，且每个值的分布概率大约为50%，那么对这种字段建索引一般不会提高数据库的查询速度。
- **经常和主字段一块查询但主字段索引值比较多的表字段**

###  索引的优化(使用索引的注意事项)？

**like语句的前导模糊查询不能使用索引**：

```sql
select * from doc where title like '%XX';   --不能使用索引
select * from doc where title like 'XX%';   --非前导模糊查询，可以使用索引
```

**联合索引最左前缀原则**

**不能使用索引中范围条件右边的列(范围列可以用到索引)，范围列之后列的索引全失效**

**不要在索引列上面做任何操作（计算、函数），否则会导致索引失效而转向全表扫描**

**强制类型转换会全表扫描**：字符串类型不加单引号会导致索引失效，因为mysql会自己做类型转换，相当于在索引列上进行了操作

**利用覆盖索引来进行查询操作，避免回表，减少select \* 的使用**

### 索引什么时候会失效？

- 查询条件中带有or，除非所有的查询条件都建有索引，
- like查询是以%开头，索引会失效
- 如果列类型是字符串，那在查询条件中需要将数据用引号引用起来，否则索引失效
- 索引列上参与计算，索引失效
- 违背最左匹配原则，索引失效
- 如果MySQL估计全表扫描要比使用索引要快，索引失效

## 锁

### MySQL的表级锁有哪些？作用是什么？

**元数据锁作用**：对数据库表进行操作时，会自动给这个表加上元数据锁，为了保证当用户对表执行 CRUD 操作时，其他线程对这个表结构做了变更。

**意向锁作用**：对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」，对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」。

**AUTO-INC锁：**表里的主键通常都会设置成自增的，之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值通过 **AUTO-INC 锁**实现的。

### MySQL的行级锁有哪些？作用是什么？

记录锁

间歇锁

### MySQL的执行引擎有哪些？

- InnoDB引擎提供了对事务ACID的支持，还提供了行级锁和外键的约束。
- MyISAM引擎不支持事务，也不支持行级锁和外键约束。

## 日志

### MySQL三种日志？

**undo log(回滚日志)**

undo log是Innodb存储引擎层生成的日志，主要**用于事务回滚和MVCC**

在事务没提交之前，Innodb会先记录更新前的数据到undo log中，回滚时利用 undo log 来进行回滚。每当进行一条记录进行操作(修改、删除、新增)时，要把回滚时需要的信息都记录到 undo log 里：原理是执行一条相反的操作。undo log 有两个参数：roll_pointer 指针和一个 trx_id 事务id，通过 trx_id 可以知道该记录是被哪个事务修改的；通过 roll_pointer 指针可以将这些 undo log 串成一个链表，形成版本链。

innodb存储引擎也通过ReadView + undo log实现 MVCC(多版本并发控制)。

**redo log(重做日志)**

redo log是物理日志，记录了某个数据页做了什么修改，每当执行一个事务就会产生一条或者多条物理日志。在事务提交时，先将redo log持久化到磁盘即可，不需要等到将缓存在Buffer Pool里的脏页数据持久化到磁盘。当系统崩溃时，虽然脏页数据没有持久化但是redo log已经持久化，可以根据 redo log 的内容，将所有数据恢复到最新的状态。

redo log实现了事务中的持久性，主要用于掉电等故障恢复。发生更新的时候，InnoDB会先更新内存，同时标记为脏页，然后将本次对这个页的修改以redo log的形式记录下来。InnoDB引擎会在适当的时候，由后台线程将缓存在Buffer Pool的脏页刷新到磁盘里，实现**WAL技术**。

**什么是WAL技术？**

WAL技术指的是，MySQL的写操作并不是立刻写到磁盘上，而是先写日志，然后在合适的时间再写到磁盘上。 

**什么是crash-safe？**

redo log+WAL 技术，InnoDB 就可以保证即使数据库发生异常重启，之前已提交的记录都不会丢失。

**redo log容灾恢复过程？**

如果 redo log 是完整(commit 状态)的，直接用 redo log 恢复；

如果 redo log 是预提交 prepare 但不是 commit 状态，此时要去判断 binlog 是否完整，如果完整那就提交 redo log，再用 redo log 恢复，不完整就回滚事务

**redo log是直接写入磁盘的吗？**

不是。直接写入磁盘会产生大量的 I/O 操作，redo log会写入redo log buffer，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘

**redo log buffer什么时候刷盘？**

- MySQL 正常关闭时，会触发落盘
- 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘
- InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘
- 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘

**redo log比直接落盘的优点？**

redo log 的写方式使用了追加，日志操作是**顺序写**，磁盘操作是**随机写**，MySQL 的写操作从磁盘的**随机写**变成了**顺序写**，提升语句的执行性能。

- **实现事务的持久性，让 MySQL 有 crash-safe 的能力**，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；
- **将写操作从随机写变成了顺序写**，提升 MySQL 写入磁盘的性能

**binlog(归档日志）**

Server 层生成的日志，主要**用于数据备份和主从复制**。

在完成一条更新操作后，Server 层会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写入 binlog 文件。binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作。

### redo log与bin log的区别？

- **适用对象不同**：binlog 是 MySQL 的 Server 层实现的，所有存储引擎都可以使用；redo log 是 Innodb 存储引擎实现的日志。
- **文件格式不同**：redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新。
- **写入方式不同**：binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。redo log是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。
- **用途不同**：binlog 用于备份恢复、主从复制；redo log 用于掉电等故障恢复。

### redo log和undo log区别？

redo log 记录了此次事务**完成后**的数据状态，undo log 记录了此次事务**开始前**的数据状态

### undo log是如何实现MVCC的?

通过**事务的 Read View 里的字段和记录中的两个隐藏列(trx_id 和 roll_pointer)**的比对，如果不满足可见行，就会顺着 undo log 版本链里找到满足其可见性的记录，从而控制并发事务访问同一个记录时的行为。

### 为什么有了binlog，还要有redo log？

早期版本 MySQL 里没有 InnoDB 引擎，MySQL 自带的 MyISAM引擎没有 crash-safe 的能力，binlog 日志只能用于归档。InnoDB 是另一个公司以插件形式引入 MySQL 的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力

### 被修改 Undo 页面，需要记录对应 redo log 吗？

需要。开启事务后，InnoDB 更新记录前，首先要记录相应的 undo log，如果是更新操作，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。**在内存修改该 Undo 页面后，需要记录对应的 redo log**。

### binlog的三种格式？

- **STATEMENT（默认）**：每一条修改数据的 SQL 都会被记录到 binlog 中，主从复制中 slave 端再根据 SQL 语句重现。
  - STATEMENT 有动态函数的问题，比如用了 uuid 或者 now 这些函数，在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致
- 记录行数据最终被修改成什么样了，不会出现 STATEMENT 下动态函数的问题
  - 但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句。
- 包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式

### binlog什么时候刷盘？

事务执行过程中，先把日志写到 binlog cache(Server 层的 cache)，事务提交的时候，再把 binlog cache 写到 binlog 文件中

### 为什么需要两阶段提交？

事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，造成两份日志之间的逻辑不一致。

- **如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入**。MySQL 重启后，通过 redo log 能将 Buffer Pool 恢复到新值，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行是旧值，主从不一致。
- **如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入**。由于 redo log 还没写，崩溃恢复以后这个事务无效，数据是旧值，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，这一行字段是新值，与主库的值不一致性。

所以会造成主从环境的数据不一致性。因为 redo log 影响主库的数据，binlog 影响从库的数据，redo log 和 binlog 必须保持一致。

**两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是准备(Prepare)阶段和提交(Commit)阶段**，每个阶段都由协调者(Coordinator)和参与者(Participant)共同完成。

- **prepare 阶段**：将 内部 XA 事务的 ID写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘。
- **commit 阶段**：把 内部 XA 事务的 ID写入到 binlog，然后将 binlog 持久化到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 成功，只要 binlog 写磁盘成功，redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功

### 两阶段提交有什么问题？

**磁盘 I/O 次数高**：每个事务提交都会进行两次 fsync(刷盘)，一次是 redo log 刷盘，另一次是 binlog 刷盘。

**锁竞争激烈**：两阶段提交虽然能够保证单事务两个日志的内容一致，但在多事务的情况下，却不能保证两者的提交顺序一致。在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。

### 慢查询的原因？

- **索引不足**：如果查询的表没有合适的索引，MySQL需要遍历整个表才能找到匹配的记录，这会导致查询变慢。可以通过添加索引来优化查询性能。
- **数据库设计问题**：如果数据库设计不合理，例如表过于庞大、列过多等，查询时可能需要耗费大量时间。这时可以通过优化数据库设计来解决问题。
- **数据库服务器负载过高**：如果MySQL服务器上同时运行了太多的查询，会导致服务器负载过高，从而导致查询变慢。可以通过增加服务器硬件配置或分散查询负载来解决问题。
- **查询语句复杂**：复杂的查询语句可能需要耗费更多的时间才能完成。可以尝试简化查询语句或将查询分解成多个较简单的查询语句来提高性能。
- **数据库统计信息不准确**：如果数据库统计信息不准确，MySQL可能会选择不合适的查询计划，从而导致查询变慢。可以通过更新数据库统计信息来解决问题。
