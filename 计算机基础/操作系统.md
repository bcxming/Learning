## 计算机基础

### 讲一讲什么是操作系统？

操作系统是管理计算机硬件和软件资源、给应用程序和用户提供底层抽象的一种系统软件

硬件管理、文件管理、进程管理、内存管理、安全防护、用户接口等

### 讲一讲冯诺依曼结构？

**存储器**：存储器负责存储计算机程序和数据

**中央处理器**：算术逻辑单元和控制单元

**输入设备**：键盘、鼠标

**输出设备**：显示器、打印机

**总线**：数据总线、地址总线、控制总线

### 讲一讲外中断与异常？

外部中断是由计算机系统外部事件触发的，通常与硬件设备相关

异常是由计算机系统内部事件触发的，通常与正在执行的程序或指令有关（算术异常、地址异常、系统调用等）

### CPU地址翻译是怎样实现的？

**地址翻译过程**

在分页系统中，虚拟地址由两部分组成：虚拟页号（Virtual Page Number, VPN）和页内偏移（Offset）。VPN用于标识虚拟内存中的一个页，Offset表示在这个页中的位置。地址翻译的过程主要包括以下步骤：

1. 从虚拟地址中提取VPN和Offset。
2. 使用页表（Page Table）将VPN转换为物理页框号（Physical Frame Number, PFN）。页表是操作系统维护的数据结构，用于记录虚拟页到物理页框的映射关系。每个进程都有一个独立的页表。
3. 将PFN与Offset组合成物理地址。

**页表查找与地址翻译**

页表查找是地址翻译过程中的关键步骤。在简单的单级页表系统中，页表是一个线性数组，使用VPN作为索引来查找对应的PFN。然而，对于较大的地址空间，单级页表可能会非常庞大并且浪费内存。

为了解决这个问题，多级页表被引入。在多级页表系统中，页表被划分为多级层次结构。虚拟地址被分为多个部分，每个部分用于在不同级别的页表中查找。最后一级页表包含实际的PFN。多级页表可以有效减少内存消耗，因为只需要分配实际使用的页表空间。

**页表缓存**

由于地址翻译过程需要多次访问内存，这会导致性能开销。为了加速地址翻译，现代处理器引入了一种叫做Translation Lookaside Buffer（TLB）的硬件缓存。TLB缓存了最近使用过的VPN到PFN的映射关系。当处理器需要执行地址翻译时，首先在TLB中查找。如果找到了相应的映射，就不需要再访问页表，从而减少了内存访问次数和地址翻译的延迟。这种情况称为TLB命中。如果TLB未找到相应的映射（TLB未命中），则需要访问内存中的页表进行地址翻译，然后将新的映射加入TLB。

### 讲一讲TLB？

Translation Lookaside Buffer（TLB）是一种硬件高速缓存，用于加速虚拟地址到物理地址的翻译过程。TLB位于CPU内部，存储了最近使用过的虚拟地址到物理地址的映射关系。

###  什么是局部性原理？

局部性原理描述了程序在一段时间内，对内存地址的访问倾向于集中在某个较小的地址范围内。

分类：时间局部性、空间局部性

局部性原理的应用

- **高速缓存（Cache）**： 避免了对较慢的主存的访问，这样可以大大提高程序的执行速度
- **TLB（Translation Lookaside Buffer）**： TLB是一种用于加速虚拟地址到物理地址转换的硬件缓存
- **预取策略（Prefetching）**： 预取策略是一种主动加载数据和指令到Cache或其他高速存储器的技术
- **磁盘调度（Disk Scheduling）**： 磁盘调度算法也可以利用局部性原理来提高磁盘I/O性能

### 介绍一下现代CPU指令周期

现代CPU的指令周期是指CPU执行一条指令所需的时间

- 取指（Fetch）：从内存中获取指令。
- 解码（Decode）：将指令转换为控制信号和操作数。
- 执行（Execute）：根据指令类型，执行相应的操作。
- 访存（Memory Access）：如果指令涉及到内存操作（如加载、存储），则访问内存。
- 写回（Write Back）：将执行结果写回目标寄存器。

### 讲一讲用户态与内核态，他们之间怎么切换的？

用户态和内核态是操作系统为了保护系统资源和实现权限控制而设计的两种不同的CPU运行级别

区别

- **权限**：内核态具有执行所有指令和访问所有内存空间的权限

- **代码**：内核态主要执行操作系统的内核代码

- **资源访问**：在用户态下，程序不能直接访问受保护的系统资源

切换场景

- 系统调用
- 异常
- 外部中断

### 讲一讲CPU缓存？

**类型**

- **L1缓存**：数据缓存、指令缓存、几十kB
- **L2缓存**：位于L1缓存之外，但仍然位于CPU芯片内部。L2缓存的容量通常比L1缓存大，但访问速度略慢
- **L3缓存**：位于L2缓存之外，但仍在CPU芯片内部。L3缓存的容量比L2缓存更大，但访问速度略慢。L3缓存通常在多核处理器中共享，用于在不同核之间共享数据和降低访问内存的延迟。

**常见的替换策略**

- **随机替换**：从缓存中随机选择一个条目进行替换
- **最近最少使用（LRU）**：替换缓存中最久未使用的数据或指令
- **最不经常使用（LFU）**：替换缓存中使用频率最低的数据或指令
- **先进先出（FIFO）**：替换缓存中最早进入的数据或指令

### 讲一讲CPU的缓存一致性？

**写操作的一致性**：当一个处理器对内存中的某个地址进行写操作时，需要确保其他处理器对该地址的访问能够看到这次写操作的结果。

**事务性**：多核处理器系统中的缓存一致性需要满足事务性

**缓存一致性协议**

### **MESI协议**

- **Modified（修改）**：缓存行中的数据已经被修改，与内存中的数据不一致。在此状态下，该处理器核心负责将数据写回主内存。
- **Exclusive（独占）**：缓存行中的数据与内存中的数据一致，且此数据只在当前缓存中存在。这意味着其他处理器核心的缓存中不存在该数据。
- **Shared（共享）**：缓存行中的数据与内存中的数据一致，但可能在其他处理器核心的缓存中也存在。此时，多个处理器核心都可以读取该数据。
- **Invalid（无效）**：缓存行中的数据是无效的，可能是因为其他处理器核心修改了数据，或者当前处理器核心失去了对该数据的独占权限。

MESI协议通过监控处理器核心的读写操作以及跟踪其他核心的操作来实现缓存一致性。当一个处理器核心需要执行读或写操作时，它会发送请求到其他核心，以便根据其他核心的缓存状态来更新自己的缓存行状态。例如，当一个处理器核心需要修改一份共享数据时，它会向其他拥有该数据的核心发出请求，使其将缓存行状态标记为无效。这样，修改后的数据只存在于一个核心的缓存中，确保了数据一致性。

### 讲一讲伪共享问题？

伪共享的产生主要是因为缓存行的设计。在处理器中，数据是以缓存行为单位进行存取的，而缓存行一般大小为 64 字节（可根据处理器不同而变化）。当两个处理器核心访问的数据恰好位于同一个缓存行内时，即使它们访问的是不同的变量，也会导致伪共享问题。

比如：一个变量A，一个变量B，CPU1去读A，CPU2去读B，AB刚好在一条缓存行里：

 1.线程1先去读A；此时这条缓存独占

 2.线程2去读B，此时这条缓存共享

 3.线程1修改A，此时Cache的状态已经修改，它会去通知CPU2这条缓存失效

 4.线程2写B的时候，会先把Cache写回内存，再取出cache，再写入B，但其实A与B不会互相影响。

避免方法

- **数据对齐与填充**：通过对齐数据结构或在数据结构之间添加填充，使得不同处理器核心访问的数据位于不同的缓存行内。
- **优化数据布局**：尽量使同一个缓存行内的数据是由同一个处理器核心频繁访问的，避免跨核访问。

### 常用的Linux命令？

- find 查找文件或目录的路径
- pwd 显示当前所在路径
- ls 列出当前目录所有子目录与文件
- cd 切换工作目录
- man 查看帮助手册
- grep 查找文件或其他内容里符合条件的字符串
- chmod 控制用户对文件的权限的命令
- ps 列出系统中当前运行的进程
- kill 向执行中进程发出信号

###  Linux下如何查看CPU荷载，正在运行的线程，某个端口对应的进程？

**查看CPU负载**

使用`top`命令来查看实时的系统状态，包括CPU负载、内存使用情况等；使用`uptime`命令查看系统运行时间和平均负载。

**查看正在运行的线程**

使用`ps`命令来查看当前系统中正在运行的线程。要查看所有线程（包括其他用户的线程），使用`ps -eLf`命令。

**查找某个端口对应的进程**

可以使用`netstat`或`lsof`命令。

使用`netstat`：

```bash
sudo netstat -tuln | grep :端口号
```

使用`lsof`：

```bash
sudo lsof -i :端口号
```

### Linux下如何排查CPU以及内存占用过多？

**`top`**：使用`top`命令可以实时查看系统的资源使用情况，包括CPU和内存占用。

**`ps`**：使用`ps`命令可以查看当前运行的进程。要按CPU或内存占用对进程进行排序。

- 按CPU占用排序：`ps aux --sort=-%cpu`
- 按内存占用排序：`ps aux --sort=-%mem`

**`free`**：使用`free`命令可以查看系统的内存使用情况。

**`vmstat`**：`vmstat`命令提供有关虚拟内存、进程、CPU活动等的报告。

### Linux如何查看实时的滚动日志？

使用`tail`命令查看实时的滚动日志。`tail`命令可以显示文件的最后部分，`-f`选项使命令持续输出文件的新增内容，这样就可以实时查看滚动日志。假设想查看名为`/var/log/mylogfile.log`的日志文件：

```bash
tail -f /var/log/mylogfile.log
```

## 进程和线程

### 什么是互斥锁，自旋锁呢，底层是怎么实现的？

互斥锁（Mutex）和自旋锁（Spinlock）是两种用于同步和保护共享资源的锁机制，它们都可以防止多个线程或进程同时访问共享资源

互斥锁：互斥锁的底层实现通常依赖于操作系统的原语，例如在Linux系统中使用pthread库的pthread_mutex_t数据结构来实现互斥锁。

自旋锁：自旋锁的底层实现通常依赖于原子操作和CPU指令

互斥锁和自旋锁的主要区别在于它们在等待锁时的行为：

- 当线程尝试获得已被占用的互斥锁时，它会进入阻塞状态，让出CPU资源，等待锁被释放。
- 当线程尝试获得已被占用的自旋锁时，它会不断循环检查锁是否可用，而不会让出CPU资源。

### 讲一讲死锁，死锁怎么处理？

互斥、持有等待、持有平等、循环等待

处理方法：

**预防死锁：**

- 破坏占有且等待条件：要求线程/进程在请求资源之前释放所有已经持有的资源，或者一次性请求所有需要的资源。
- 破坏循环等待条件：为所有资源分配一个全局的顺序，并要求线程/进程按照这个顺序请求资源。

**避免死锁**： 避免死锁的方法是在运行时动态地检查资源分配情况，以确保系统不会进入不安全状态。银行家算法是一种著名的避免死锁的算法，通过模拟资源分配过程来判断是否会产生死锁，如果会产生死锁，则拒绝分配资源。

**检测和恢复死锁：**

- 终止线程/进程：强制终止一个或多个死锁中的线程/进程，从而释放其持有的资源
- 动态资源分配：在检测到死锁后，尝试动态地分配资源，以解除死锁

### 什么是读写锁？

读写锁在实现时通常依赖于底层的操作系统原语。例如，在Linux系统中，可以使用pthread库中的pthread_rwlock_t数据结构来实现读写锁。

根据实现方式的不同，读写锁可能需要处理读写操作之间的优先级问题。

### Linux同步机制？

互斥锁：Linux中的互斥锁是通过POSIX线程库（pthread）实现的

读写锁：Linux中的读写锁也是通过POSIX线程库（pthread）实现的

条件变量：pthread_cond_t数据结构提供了条件变量的实现

信号量：Linux系统提供了System V信号量和POSIX信号量两种实现

### 信号量是如何实现的？

**基本实现原理**

1. **初始化**：信号量在创建时需要进行初始化，通常将计数器设置为允许同时访问共享资源的最大数量。
2. **Wait（P）操作**：当一个线程或进程想要访问共享资源时，会执行wait操作。在wait操作中，信号量的计数器减1。如果计数器的值为负数，表示没有可用的资源，执行wait操作的线程/进程将被阻塞，直到有资源可用。
3. **Post（V）操作**：当一个线程或进程完成对共享资源的访问后，会执行post操作。在post操作中，信号量的计数器加1。如果计数器的值小于等于0，表示有等待的线程/进程，此时会唤醒一个被阻塞的线程/进程。

信号量的实现依赖于底层操作系统原语，以保证wait和post操作的原子性。在Linux系统中，信号量有两种实现方式：System V信号量和POSIX信号量。

**System V信号量**

**POSIX信号量**：POSIX信号量使用sem_t数据结构，并通过一组函数（如sem_init、sem_wait、sem_trywait、sem_post和sem_destroy）提供信号量操作。POSIX信号量在现代Linux系统中较为常用，因为它们具有较好的可移植性和性能。

### 生产者消费者问题？

常见的解决方案是使用条件变量和互斥锁：

1. 初始化一个互斥锁，用于保护对共享缓冲区的访问。

2. 初始化两个条件变量：一个表示缓冲区非空（可以供消费者取出数据），另一个表示缓冲区非满（可以供生产者放入数据）。

3. 生产者在生产数据时：

   a. 获取互斥锁，保护共享缓冲区的访问。

   b. 当缓冲区已满时，等待缓冲区非满的条件变量。

   c. 将数据项放入缓冲区。

   d. 通知缓冲区非空的条件变量，表示有数据可供消费者取出。

   e. 释放互斥锁。

4. 消费者在消费数据时：

   a. 获取互斥锁，保护共享缓冲区的访问。

   b. 当缓冲区为空时，等待缓冲区非空的条件变量。

   c. 从缓冲区中取出数据项。

   d. 通知缓冲区非满的条件变量，表示有空间可供生产者放入数据。

   e. 释放互斥锁。

### 哲学家进餐问题？

1. **资源分级**：为每根筷子分配一个优先级，每个哲学家总是先拿起优先级较高的筷子，再拿起优先级较低的筷子。这种方法可以避免死锁，因为至少有一个哲学家可以拿到两根筷子。
2. **限制同时进餐人数**：限制同时进餐的哲学家数量，例如最多允许四位哲学家同时进餐。这种方法可以避免死锁，因为总是至少有一位哲学家能够拿到两根筷子。
3. **奇偶分组**：将哲学家分为奇数和偶数两组，每组哲学家在不同的时间段尝试拿起筷子。例如，奇数哲学家先拿起左边的筷子，再拿起右边的筷子；偶数哲学家先拿起右边的筷子，再拿起左边的筷子。这种方法可以避免死锁，因为每个时间段内总是有一位哲学家能够拿到两根筷子。

上述解决方案可以避免死锁，但并不一定能完全解决饥饿问题。例如，当某些哲学家持续拿不到筷子时，他们可能饿死。要解决饥饿问题，可以采用公平调度策略，例如轮询或优先级调度。此外，可以使用其他同步原语，如读写锁或监视器，来进一步优化解决方案。

### 进程、线程、协程区别与联系？

**进程（Process）**： 

1、每个进程拥有独立的内存空间、文件描述符、寄存器状态等资源。

2、进程之间的资源是相互隔离的，因此进程间通信需要通过操作系统提供的特定机制（如管道、消息队列、共享内存等）进行。

3、由于进程拥有独立的资源，所以进程间的切换和调度开销较大。

**线程（Thread）**： 

1、线程是操作系统调度执行的最小单位，是进程内的一个执行流。

2、一个进程可以拥有多个线程，这些线程共享进程的资源（如内存空间、文件描述符等），线程相较于进程，上下文切换和调度开销较小。

3、由于线程共享相同的资源，线程间通信相对简单，可以直接通过共享变量、锁等方式进行。

**协程（Coroutine**）： 

1、协程是一种用户态的轻量级线程，它的调度和切换完全由程序控制，不依赖于操作系统的调度。

2、协程之间共享线程的资源，因此协程间通信也可以通过共享变量、锁等方式进行。协程的优势在于能够轻松地实现高并发，因为协程切换和调度的开销非常小。

3、协程适用于I/O密集型任务，通过异步I/O可以有效地提高程序的性能。

**联系**：线程属于进程，协程属于线程

### 讲一讲用户线程与内核线程？

用户线程是在用户空间创建和管理的线程。它们由用户级的线程库（如POSIX线程库Pthreads）来实现，而不是直接由操作系统内核管理。

**优点**：

1. **轻量级**：用户线程的创建、切换和销毁不需要进入内核态，因此开销较小，速度快。
2. **灵活性高**：用户可以根据应用需求定制自己的调度算法。
3. **跨平台**：因为用户线程库通常独立于操作系统，所以可以更容易地移植到不同的平台上。

**缺点**：

1. **多线程阻塞问题**：如果一个用户线程执行了一个阻塞系统调用（例如I/O操作），整个进程会被阻塞，因为内核不知道有多个用户线程存在。
2. **无法利用多处理器**：由于内核只看到单个进程，不知道其内部的多个用户线程，这使得不能在多处理器系统中并行运行多个用户线程。

内核线程是由操作系统内核创建和管理的线程。每个内核线程都由内核进行调度和管理，并且与硬件紧密交互。

**优点**：

1. **真正的并发**：内核线程可以在多处理器系统中并行运行，从而提高程序的执行效率。
2. **无需担心阻塞**：一个内核线程阻塞不会影响其他线程，因为内核能够继续调度其他线程。

**缺点**：

1. **重量级**：内核线程的创建、切换和销毁需要进入内核态，开销较大。
2. **复杂性**：内核负责管理线程，需要更多的系统资源和复杂的调度机制。

### 混合模型

一些现代操作系统采用混合模型，将用户线程和内核线程结合起来使用。例如，许多UNIX系统和Windows NT系列操作系统使用这种方法。该模型允许用户线程映射到内核线程，使得既能享受用户线程的灵活性，又能利用内核线程的优势，如并发和避免阻塞。

### 一个进程可以创建多少个线程？

**操作系统限制**：查看`/proc/sys/kernel/threads-max`文件获取系统级别的最大线程数限制，`ulimit`命令查看和设置每个进程的线程数限制

**系统资源**：一个进程可以创建的线程数受到可用内存和CPU资源的限制

### 进程的调度算法？

时间片轮转，先到先得（FCFS)，最短任务优先(SJF)，最短完成时间优先(STCF)，多级队列（MLQ）

### 进程间通信方式？

**管道：**内核中存在一定缓冲区，并且传输的数据是字节流

**消息队列：**在内核中的数据结构是一个单链表构成的队列，最初会有个消息头部指针，保存着消息队首与相应的权限

**信号量:**主要有两个原语，P操作与V操作

**共享内存**:共享内存不需要先拷贝到内核空间中, 它允许一个或者多个进程所在的虚拟地址空间中映射相同的物理页，从而进行通信

**信号**：管道、消息队列、共享内存主要是关注数据传输设计，而信号的作用是**单项的事件通知**能力。一个进程会为一些特定的信号注册回调函数。

### 父子进程

**父进程（Parent Process）和子进程（Child Process）**： 在操作系统中，进程可以创建其他进程。创建新进程的进程称为父进程，新创建的进程称为子进程。这种关系形成了一个进程树结构，其中根进程（如 Unix 和类 Unix 系统中的 init 进程，进程ID为1）是所有其他进程的祖先。在 Unix 和类 Unix 系统中，可以通过 `fork()` 系统调用创建子进程。`fork()` 调用会复制当前进程的地址空间和环境，并创建一个新的进程。子进程从 `fork()` 调用处继续执行，并继承父进程的大部分属性（如文件描述符、环境变量等）。父子进程可以通过 `getpid()`（获取当前进程ID）和 `getppid()`（获取父进程ID）系统调用来识别彼此。

###  多进程与多线程怎么选择？

1、**容错性和隔离**：进程更好

2、**开发和维护难度**：线程更好

3、**资源需求**：线程更好

### 什么情况下，进程会进行切换？

时间片到期

高优先级进程就绪

进程自愿让出CPU

进程阻塞

中断处理

## 内存管理

### 虚拟内存的作用

它允许将计算机的物理内存划分为独立的、隔离的虚拟内存块，每个虚拟内存块都由操作系统或虚拟机管理

**进程保护**：每个进程都有自己的虚拟地址空间，这样就能防止一个进程意外或恶意地访问另一个进程的内存。

**易用性**：内存虚拟化简化了内存管理，使得程序员无需关注物理内存的具体细节。

**资源管理：**可以分配比实际物理内存大的虚拟地址空间

逻辑地址由程序和CPU生成，用于表示进程内部的内存引用。物理地址表示实际内存硬件中的位置，用于在物理内存中访问数据。逻辑地址和物理地址之间的映射由操作系统和内存管理单元（MMU）完成，以实现内存虚拟化、进程隔离和资源管理等功能。

### 操作系统在对内存管理时做了什么？

**内存分配**

**地址空间管理：**操作系统为每个进程创建和管理一个虚拟地址空间

**内存保护**

**内存回收**

**页面置换：**LRU、FIFO

**内存优化**：操作系统通过一些技术来优化内存使用，提高内存资源的利用率（内存去重、内存压缩、按需分配）

### 讲一讲物理内存与虚拟内存的映射机制？

虚拟内存到物理内存的映射方式一般有分段和分页两种，由于分段机制内存碎片较多，常用的是分页机制。

- **分页机制**： 在分页系统中，虚拟内存和物理内存都被划分为固定大小的单元，称为页（page）。虚拟页的大小与物理页相同，通常为4KB或更大。
- **页表**： 页表是一种数据结构，用于存储虚拟页到物理页的映射关系。每个进程都有自己的页表，由操作系统管理。页表中的每个条目包含一个虚拟页号和对应的物理页号。当CPU访问虚拟内存时，MMU会使用页表将虚拟地址转换为物理地址。
- **地址转换**： 虚拟地址通常由两部分组成：虚拟页号（VPN）和页内偏移（offset）。虚拟页号用于查找页表中相应的物理页号，而页内偏移表示在物理页中的具体位置。地址转换过程如下：
  - CPU生成一个虚拟地址。
  - MMU从虚拟地址中提取虚拟页号（VPN）和页内偏移（offset）。
  - MMU使用VPN在页表中查找对应的物理页号（PPN）。
  - MMU将物理页号（PPN）与页内偏移（offset）组合成物理地址。
  - CPU使用物理地址访问物理内存。
- **页面置换和缺页中断**：当虚拟页尚未加载到物理内存时，发生页面缺失（page fault）。在这种情况下，操作系统需要从磁盘或其他存储设备中加载所需的虚拟页，并将其映射到物理内存。为了腾出空间，操作系统可能需要选择一个已加载的页面，将其换出到磁盘。页面置换算法（如LRU、FIFO等）用于决定哪个页面应该被换出。
- **多级页表**： 多级页表是一种用于减少页表大小的技术。在具有大量虚拟地址空间的系统中，使用单级页表可能导致浪费大量内存。多级页表通过将虚拟地址空间划分为多个层次来减小页表的大小。每个层次都有自己的页表，只有在需要时才会分配。这样可以大大减少内存开销。
- **快表（TLB）**： 快表，是一种硬件缓存，用于加速虚拟地址到物理地址的转换过程。TLB将最近使用过的虚拟地址到物理地址的映射存储在高速缓存中，以便快速查找。当MMU需要转换一个虚拟地址时，它首先检查TLB是否包含所需的映射。如果TLB中存在映射，MMU可以避免访问内存中的页表，从而加速地址转换过程。
- **内存分配策略**： 操作系统使用不同的内存分配策略来管理虚拟内存和物理内存之间的映射。按需分配（demand paging）是一种常用的策略，它只在进程实际访问虚拟内存时才将虚拟页加载到物理内存。预取（prefetching）是另一种策略，它根据进程的访问模式提前加载可能需要的虚拟页，以减少页面缺失的开销。
- **内存共享**： 内存共享是一种允许多个进程访问相同物理内存区域的技术。通过将不同进程的虚拟地址映射到同一物理页，操作系统可以实现内存共享。这种技术在共享库、进程间通信和内存去重等场景中非常有用。

### 什么是换页机制？

当物理内存不足以容纳所有当前需要的页面时，操作系统必须决定哪些页面应该从物理内存中移出，以腾出空间给新的页面。这一过程称为“换页”，这样可以在有限的物理内存中运行更多的进程。

### 操作系统中的缺页中断？

在程序访问到了一个尚未加载到物理内存（RAM）的虚拟内存地址时。当程序试图访问这个地址时，CPU会触发一个缺页中断，通知操作系统需要加载相应的内存页面。缺页中断是内存管理的一部分，尤其是在虚拟内存系统中。

1. 检查虚拟地址是否有效，即是否存在对应的虚拟内存页。如果无效，操作系统将向程序返回一个错误，可能导致程序终止。
2. 如果虚拟地址有效，操作系统会查找一个空闲的物理内存页帧来存储所需的虚拟内存页。
3. 如果没有空闲的物理内存页帧，操作系统会选择一个当前已加载的页面进行替换，将其写回磁盘（如果被修改过）以释放页帧。
4. 操作系统从磁盘中读取所需的虚拟内存页并将其加载到新分配的物理内存页帧中。
5. 更新页表，将虚拟地址映射到新分配的物理内存页帧。
6. 恢复程序执行，使程序能够继续访问所需的虚拟内存地址。

缺页中断会对系统性能产生影响。为了减轻缺页中断对性能的影响，操作系统采用了以下优化策略：

- **缓存与缓冲**：操作系统通过使用缓存和缓冲区来减少磁盘访问次数。缓存可以暂存最近访问过的磁盘数据，提高数据读取速度。缓冲区可以合并多个连续的写操作，减少磁盘写入次数。
- **预取**：预取是一种预测性技术，它根据程序的访问模式来预先加载可能被访问的内存页，从而减少缺页中断的发生。
- **页置换算法**：为了提高内存利用效率，操作系统使用页置换算法来决定在发生缺页中断时，应该替换哪个物理内存页帧。常见的页置换算法有：最近最少使用（LRU）、最不经常使用（LFU）和时钟算法等。
- **写回策略与写穿策略**：写回策略允许操作系统在将内存页写回磁盘之前缓存修改过的数据，减少磁盘写入次数。写穿策略则要求每次修改内存页时都将更改立即写回磁盘，这可以确保数据一致性，但会增加磁盘写入次数。

### 换页时的抖动是什么？

当系统频繁发生缺页中断并进行换页操作时，会导致系统性能急剧下降。在抖动现象下，CPU大部分时间都用于处理缺页中断和换页操作，而不是执行实际的应用程序。这导致系统的吞吐量和响应时间变差，从而使得系统表现出低效的运行状态。

**过高的内存需求**：当一个或多个运行中的进程所需的内存空间超过了可用的物理内存时，操作系统需要频繁地在物理内存和磁盘之间交换内存页面。

**不恰当的内存分配**：如果操作系统没有合理地分配内存资源给各个进程。

**不合理的页置换算法**：如果操作系统采用的页置换算法不能准确地预测进程将访问哪些内存页面。

解决办法：内存扩展、调整工作负载、使用交换空间

### 进程的内存分布？

进程是操作系统中一个运行中的程序实例。在操作系统中，每个进程都拥有独立的虚拟内存空间，以便存储其代码、数据和运行时所需的信息。

内核空间

栈

内存映射区

堆

bss未初始化全局变量

data已初始化全局变量

代码段

### 堆上建立对象快，还是栈上建立对象块？

为什么

- **内存管理效率**：栈上分配内存在编译的时候就已经决定好了，而堆上分配内存需要先找到一块空闲区域，再去分配，会慢一些。
- **缓存局部性**：由于栈上分配的内存是连续的且与程序执行顺序密切相关，因此栈上的对象通常具有更好的缓存局部性。堆上分配的内存可能在物理地址上不连续，导致缓存命中率降低，从而影响程序执行速度。

好处

- **减少碎片化**：栈上分配的内存通常是连续的，减少了内存碎片化的问题。而堆上分配的内存可能会导致碎片化，因为动态分配和释放内存可能导致内存空间出现不连续的空闲区域。
- **释放对象**：当在栈上分配对象时，对象会在离开作用域时自动释放，无需程序员显式进行内存释放。而在堆上分配对象时，需要程序员手动释放内存（例如使用C++中的delete或C语言中的free），否则可能导致内存泄漏。

坏处

- 当对象需要在函数调用之间持续存在或者需要动态扩展时，堆上分配对象可能是更好的选择
- 栈空间的大小通常受到限制

### 页置换算法有哪些？

最佳置换算法（Optimal Page Replacement Algorithm）

先进先出算法（FIFO Page Replacement Algorithm）

最近最少使用算法（Least Recently Used Algorithm，LRU）

随机置换算法（Random Page Replacement Algorithm）

### 讲一讲malloc是怎么实现的？

- **初始化内存池**：`malloc`首次调用时，通常会初始化内存池。内存池是预先分配的一大块内存空间，用于满足后续内存分配请求。初始化过程包括从操作系统请求内存（如使用`sbrk`或`mmap`系统调用），并建立数据结构来跟踪可用的内存块（称为free list）。
- **查找合适的内存块**：当`malloc`收到内存分配请求时，它会在free list中查找一个大小满足需求的内存块。内存块查找策略可能有所不同，如首次适配（first fit）、最佳适配（best fit）或最差适配（worst fit）等。策略选择会影响内存分配的性能和内存碎片化程度。如果找不到足够大小的内存，它会从新向操作系统申请，申请大小小于128KB用brk，大于128KB时用mmap。
- **分割内存块**：如果找到的内存块大小远大于请求的内存大小，`malloc`可能会将其分割成两部分。一部分用于满足当前请求，另一部分保留在free list中以供后续分配使用。
- **更新数据结构**：`malloc`将找到的内存块从free list中移除，并更新相关的数据结构。此外，`malloc`通常会在返回的内存块前附加一些元数据（如内存块大小），以便于后续的内存释放（`free`）和重新分配（`realloc`）操作。
- **返回内存块地址**：`malloc`返回分配的内存块地址，供程序使用。需要注意的是，分配的内存块内容可能是未初始化的，需要在使用前进行适当的初始化操作。

### 讲一讲mmap是怎么实现的？

1. **参数检查**：在应用程序调用`mmap`时，操作系统首先检查参数的合法性，包括文件描述符、映射长度、访问权限、文件偏移等。如果参数无效或非法，操作系统将返回错误。

2. **创建虚拟内存区域（VMR）**：操作系统为请求的映射创建一个虚拟内存区域，该区域的长度由调用参数指定。创建VMR时，操作系统会为其分配一个连续的虚拟地址范围，并在进程的虚拟内存地址空间中记录相关信息。

3. **建立文件与虚拟内存区域的关联：**操作系统将要映射的文件与新创建的虚拟内存区域建立关联。这种关联可以是私有（private）或共享（shared）。私有映射意味着对映射区域的修改不会影响原始文件，而共享映射则意味着修改会同步到原始文件。关联信息通常存储在内核中的页表或其他数据结构中。

4. **延迟加载**：在大多数情况下，`mmap`并不会立即将文件内容加载到内存中。相反，它采用一种称为延迟加载（lazy loading）的策略，仅在应用程序实际访问映射区域时才加载所需的文件内容。这种策略可以提高性能并减少不必要的内存使用。

5. **缺页处理**：当应用程序访问尚未加载的映射区域时，操作系统会收到一个缺页中断。在处理缺页中断时，操作系统会查找与虚拟地址关联的文件和偏移，将所需的文件内容加载到物理内存中，并更新页表以建立虚拟地址到物理地址的映射。之后，应用程序可以继续访问映射区域。

6. **内存回写**：对于共享映射，应用程序对映射区域的修改需要同步到原始文件。操作系统通常采用一种称为写回（write-back）的策略，即在一段时间后或内存压力增大时将修改后的内存内容写回到文件。在某些情况下，应用程序可以通过调用`msync`来显式地同步内存和文件内容。

7. **释放内存映射**：当应用程序不再需要内存映射时，可以通过调用`munmap`系统调用来释放映射区域。操作系统在收到`munmap`调用时，会执行以下操作：

   a. 如果映射区域有未写回的修改内容，操作系统会将这些内容写回到原始文件（如果是共享映射）。

   b. 操作系统将释放与映射区域关联的物理内存页。

   c. 操作系统从进程的虚拟内存地址空间中删除映射区域，并清除与该区域关联的页表条目和其他内核数据结构。

### 共享内存是如何实现的？

共享内存机制可以提高数据传输效率，因为它避免了数据复制和内核与用户空间之间的上下文切换。

- **创建共享内存区域**：首先需要创建一个共享内存区域。在Unix和类Unix系统中，这可以通过`shmget`系统调用来实现。`shmget`创建一个共享内存标识符（Shared Memory Identifier），用于唯一标识共享内存区域。在Windows系统中，可以使用`CreateFileMapping`函数来创建一个内存映射文件。
- **将共享内存区域映射到进程地址空间**：每个需要访问共享内存区域的进程需要将其映射到自己的虚拟地址空间。在Unix和类Unix系统中，可以使用`shmat`系统调用来完成映射；在Windows系统中，可以使用`MapViewOfFile`函数。映射操作会返回一个指向共享内存区域的指针，进程可以通过该指针访问共享数据。
- **读写共享内存**：进程可以通过映射到其地址空间的共享内存区域来读写数据。为避免数据竞争和不一致，进程之间需要协调对共享内存的访问。这通常通过同步原语（如互斥锁、信号量等）来实现。
- **取消映射共享内存区域**：当进程不再需要访问共享内存时，需要将其从虚拟地址空间中取消映射。在Unix和类Unix系统中，可以使用`shmdt`系统调用；在Windows系统中，可以使用`UnmapViewOfFile`函数。
- **删除共享内存区域**：当所有进程都不再需要共享内存区域时，需要将其删除以释放系统资源。在Unix和类Unix系统中，可以使用`shmctl`系统调用（带有`IPC_RMID`命令）来删除共享内存区域；在Windows系统中，可以使用`CloseHandle`函数关闭内存映射文件的句柄。

### 文件系统

### 什么是硬链接与符号连接？

- **硬链接**是文件的多个名字，共享同一份数据。
- **软链接**是指向文件或目录的快捷方式，如果目标不存在，链接就失效。

硬链接（hard link）和符号链接（symbolic link，也称为软链接）是Unix和类Unix文件系统中两种不同的文件链接类型。它们用于创建文件或目录的引用。

**硬链接**

硬链接是文件系统中一个文件的额外引用。在Unix和类Unix文件系统中，每个文件都有一个称为inode的数据结构来存储文件的元数据，例如文件权限、所有者、大小等。每个文件都有一个或多个文件名（硬链接），它们指向相应的inode。换句话说，硬链接是文件名和inode之间的关联。

硬链接的特点如下：

- 硬链接不能跨文件系统。由于硬链接直接关联到inode，它只能在同一个文件系统中创建。
- 硬链接不能引用目录。这是为了防止文件系统中出现循环引用和其他不一致性问题。
- 删除一个文件的所有硬链接会导致文件被删除。当一个文件的最后一个硬链接被删除时，文件系统将释放该文件的inode以及占用的存储空间。
- 硬链接不影响原始文件的访问。所有硬链接都指向相同的inode，因此访问任何一个硬链接实际上是访问原始文件。

**符号链接**

符号链接是一种特殊的文件，它包含指向另一个文件或目录的路径。与硬链接直接关联到inode不同，符号链接通过路径名来引用目标文件。当用户或应用程序访问符号链接时，文件系统会自动将其重定向到目标路径。

符号链接的特点如下：

- 符号链接可以跨文件系统。由于符号链接通过路径名引用目标文件，它可以链接到其他文件系统中的文件或目录。
- 符号链接可以引用目录。这使得符号链接在文件系统组织和目录结构管理中非常有用。
- 删除符号链接不会影响目标文件。当删除一个符号链接时，只有链接本身被删除，而目标文件保持不变。
- 符号链接可能引起死链接（dangling link）。如果目标文件被删除或移动，符号链接将指向一个不存在的路径，导致死链接。

## 服务器编程

###  select poll epoll的区别与联系？

select：文件描述符数量限制、需要遍历

poll：突破文件描述符限制

epoll

1、`epoll`使用事件驱动的方式来处理I/O操作，当有I/O事件发生时，`epoll`可以立即得到通知，而无需遍历整个文件描述符集合。

2、每次调用`epoll`时无需重新设置文件描述符集合

一般来说，epoll的效率是要比select和poll高的，但是对于活动连接较多的时候，由于回调函数触发的很频繁，其效率不一定比select和poll高。所以epoll在连接数量很多，但活动连接较小的情况性能体现的比较明显。

### 边缘触发与条件触发分别是什么？

边缘触发的缺点是我们需要确保在收到通知后处理所有相关数据，否则可能会遗漏某些事件。

条件触发的缺点是它可能导致大量的事件通知，从而增加处理开销。

### 讲一讲client-server通信双方API调用过程？

**服务器端 API 调用过程：**

1. 创建套接字（socket）：服务器端首先创建一个套接字。在 C 语言中，可以使用 `socket()` 函数创建一个新的套接字。
2. 绑定地址（bind）：然后，服务器将套接字绑定到指定的 IP 地址和端口。这可以使用 `bind()` 函数完成。
3. 监听连接（listen）：服务器将套接字设置为监听模式，以便接受来自客户端的连接请求。这可以通过调用 `listen()` 函数实现。
4. 接受连接（accept）：当客户端发起连接请求时，服务器使用 `accept()` 函数接受该连接。`accept()` 函数返回一个新的套接字，用于与客户端进行通信。
5. 接收数据（recv）：服务器使用 `recv()` 或类似的函数从客户端接收数据。这些函数通常会阻塞，直到收到数据。
6. 发送数据（send）：服务器根据客户端的请求处理数据并生成响应。然后，服务器使用 `send()` 或类似的函数将响应数据发送回客户端。
7. 关闭连接（close）：完成通信后，服务器使用 `close()` 或类似的函数关闭与客户端的连接。服务器可以继续接受其他客户端的连接。

**客户端 API 调用过程：**

1. 创建套接字（socket）：与服务器类似，客户端使用 `socket()` 函数创建一个新的套接字。
2. 连接服务器（connect）：客户端使用 `connect()` 函数发起对服务器的连接请求。这需要指定服务器的 IP 地址和端口。
3. 发送数据（send）：连接建立后，客户端使用 `send()` 或类似的函数向服务器发送请求数据。
4. 接收数据（recv）：客户端使用 `recv()` 或类似的函数接收来自服务器的响应数据。这些函数通常会阻塞，直到收到数据。
5. 关闭连接（close）：通信完成后，客户端使用 `close()` 或类似的函数关闭与服务器的连接。

### 阻塞IO、非阻塞IO有什么区别？怎么判断写文件时Buffer已经写满？

当一个I/O操作（如读或写）发起时，如果数据还没有准备好（例如，等待数据从磁盘读取或从网络接收），则调用者（通常是一个线程或进程）是否会被阻塞

在阻塞IO模式下，当写入操作发起时，如果Buffer已满，调用者会被阻塞，直到Buffer有足够的空间容纳新的数据。在这种情况下不需要担心Buffer是否已满，因为操作系统会自动处理这个问题。

在非阻塞IO模式下，当写入操作发起时，如果Buffer已满，调用者会立即收到一个错误码（例如，表示资源不可用）。在这种情况下需要根据错误码来判断Buffer是否已满，并在适当的时间点再次尝试写入操作。通常，你可以结合I/O多路复用技术来监听文件描述符的可写事件，以便在Buffer有空间时得到通知。

### 同步与异步的区别，阻塞与非阻塞的区别？

同步和异步关注的是调用者与被调用者之间的关系，同步操作需要等待结果，而异步操作可以立即返回。阻塞和非阻塞关注的是I/O操作的行为，阻塞操作会导致调用者等待，而非阻塞操作可以立即返回。这两者之间可以组合形成不同的操作模式，例如同步阻塞、同步非阻塞、异步阻塞和异步非阻塞。

### 讲一讲Rector模式与Proactor模式？

Reactor 模式和 Proactor 模式都是处理并发 I/O 事件的设计模式。它们各自的核心思想是将 I/O 操作与实际处理逻辑解耦，以便在高并发环境下更有效地处理请求。
